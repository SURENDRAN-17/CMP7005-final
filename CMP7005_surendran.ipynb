{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SURENDRAN-17/CMP7005-final/blob/main/CMP7005_surendran.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e01506bf",
      "metadata": {
        "id": "e01506bf",
        "outputId": "c291d294-2f1b-4ba1-b4cb-2421b87546d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/mnt/data/PRSA_Data_extracted/PRSA_Data_20130301-20170228/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-245e39c18103>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load all the CSV files into a dictionary of dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdataframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/PRSA_Data_extracted/PRSA_Data_20130301-20170228/'"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Directory containing the dataset files\n",
        "data_dir = \"/mnt/data/PRSA_Data_extracted/PRSA_Data_20130301-20170228/\"\n",
        "\n",
        "# Load all the CSV files into a dictionary of dataframes\n",
        "data_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
        "dataframes = {}\n",
        "\n",
        "for file in data_files:\n",
        "    file_path = os.path.join(data_dir, file)\n",
        "    key = file.split('_')[2]  # Extract site name as key\n",
        "    dataframes[key] = pd.read_csv(file_path)\n",
        "\n",
        "# Combine all dataframes into one for analysis\n",
        "combined_df = pd.concat(dataframes.values(), keys=dataframes.keys(), names=[\"Site\", \"Index\"])\n",
        "combined_df.reset_index(level=0, inplace=True)\n",
        "combined_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xUPJQ1rDsgj3"
      },
      "id": "xUPJQ1rDsgj3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87a83072",
      "metadata": {
        "id": "87a83072"
      },
      "outputs": [],
      "source": [
        "\n",
        "# General Information about the dataset\n",
        "print(combined_df.info())\n",
        "\n",
        "# Checking for missing values\n",
        "missing_values = combined_df.isnull().sum()\n",
        "\n",
        "# Handling missing values (example: filling with mean)\n",
        "combined_df.fillna(combined_df.mean(), inplace=True)\n",
        "\n",
        "# Summary statistics\n",
        "summary_stats = combined_df.describe()\n",
        "\n",
        "# Visualization: Pairplot for relationships\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.heatmap(combined_df.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title('Missing Values Heatmap')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d0e71bb",
      "metadata": {
        "id": "7d0e71bb"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Select features and target for a simple regression model\n",
        "features = ['PM2.5', 'PM10', 'NO2', 'CO', 'O3', 'SO2']\n",
        "target = 'TEMP'\n",
        "\n",
        "# Drop rows with missing target values\n",
        "model_data = combined_df.dropna(subset=[target])\n",
        "X = model_data[features]\n",
        "y = model_data[target]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model training\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Model evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d720be2",
      "metadata": {
        "id": "5d720be2"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tkinter as tk\n",
        "from tkinter import ttk\n",
        "\n",
        "def show_data_overview():\n",
        "    overview_window = tk.Toplevel(root)\n",
        "    overview_window.title(\"Data Overview\")\n",
        "    text = tk.Text(overview_window, wrap='word')\n",
        "    text.insert('1.0', str(combined_df.describe()))\n",
        "    text.pack(expand=True, fill='both')\n",
        "\n",
        "# GUI Application\n",
        "root = tk.Tk()\n",
        "root.title(\"Air Quality Analysis\")\n",
        "\n",
        "main_frame = ttk.Frame(root)\n",
        "main_frame.pack(fill='both', expand=True)\n",
        "\n",
        "overview_button = ttk.Button(main_frame, text=\"Data Overview\", command=show_data_overview)\n",
        "overview_button.pack(pady=10)\n",
        "\n",
        "root.mainloop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0314af33",
      "metadata": {
        "id": "0314af33"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Ensure to commit your work using GitHub.\n",
        "# Example Git commands:\n",
        "# git add .\n",
        "# git commit -m \"Initial commit: Data analysis tasks 1 to 4 completed\"\n",
        "# git push origin main\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# File paths\n",
        "files = [\n",
        "    'PRSA_Data_Dongsi_20130301-20170228.csv',\n",
        "    'PRSA_Data_Guanyuan_20130301-20170228.csv',\n",
        "    'PRSA_Data_Gucheng_20130301-20170228.csv',\n",
        "    'PRSA_Data_Huairou_20130301-20170228.csv',\n",
        "    'PRSA_Data_Nongzhanguan_20130301-20170228.csv',\n",
        "    'PRSA_Data_Shunyi_20130301-20170228.csv'\n",
        "]\n",
        "\n",
        "# Load and merge datasets\n",
        "dataframes = [pd.read_csv(file) for file in files]\n",
        "combined_data = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Display the first few rows and information about the combined dataset\n",
        "print(combined_data.head())\n",
        "print(combined_data.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I1iNNhchUSH",
        "outputId": "bc247fee-45db-4f81-8273-a51e41db5318"
      },
      "id": "-I1iNNhchUSH",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   No  year  month  day  hour  PM2.5  PM10  SO2   NO2     CO    O3  TEMP  \\\n",
            "0   1  2013      3    1     0    9.0   9.0  3.0  17.0  300.0  89.0  -0.5   \n",
            "1   2  2013      3    1     1    4.0   4.0  3.0  16.0  300.0  88.0  -0.7   \n",
            "2   3  2013      3    1     2    7.0   7.0  NaN  17.0  300.0  60.0  -1.2   \n",
            "3   4  2013      3    1     3    3.0   3.0  5.0  18.0    NaN   NaN  -1.4   \n",
            "4   5  2013      3    1     4    3.0   3.0  7.0   NaN  200.0  84.0  -1.9   \n",
            "\n",
            "     PRES  DEWP  RAIN   wd  WSPM station  \n",
            "0  1024.5 -21.4   0.0  NNW   5.7  Dongsi  \n",
            "1  1025.1 -22.1   0.0   NW   3.9  Dongsi  \n",
            "2  1025.3 -24.6   0.0  NNW   5.3  Dongsi  \n",
            "3  1026.2 -25.5   0.0    N   4.9  Dongsi  \n",
            "4  1027.1 -24.5   0.0  NNW   3.2  Dongsi  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 210384 entries, 0 to 210383\n",
            "Data columns (total 18 columns):\n",
            " #   Column   Non-Null Count   Dtype  \n",
            "---  ------   --------------   -----  \n",
            " 0   No       210384 non-null  int64  \n",
            " 1   year     210384 non-null  int64  \n",
            " 2   month    210384 non-null  int64  \n",
            " 3   day      210384 non-null  int64  \n",
            " 4   hour     210384 non-null  int64  \n",
            " 5   PM2.5    205878 non-null  float64\n",
            " 6   PM10     207256 non-null  float64\n",
            " 7   SO2      206018 non-null  float64\n",
            " 8   NO2      203760 non-null  float64\n",
            " 9   CO       199227 non-null  float64\n",
            " 10  O3       204672 non-null  float64\n",
            " 11  TEMP     210171 non-null  float64\n",
            " 12  PRES     210170 non-null  float64\n",
            " 13  DEWP     210166 non-null  float64\n",
            " 14  RAIN     210175 non-null  float64\n",
            " 15  wd       209203 non-null  object \n",
            " 16  WSPM     210207 non-null  float64\n",
            " 17  station  210384 non-null  object \n",
            "dtypes: float64(11), int64(5), object(2)\n",
            "memory usage: 28.9+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and merge datasets\n",
        "dataframes = [pd.read_csv(file) for file in files]\n",
        "combined_data = pd.concat(dataframes, ignore_index=True)"
      ],
      "metadata": {
        "id": "mUm9Md5tjLqg"
      },
      "id": "mUm9Md5tjLqg",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the number of rows and columns\n",
        "print(\"Number of rows:\", combined_data.shape[0])\n",
        "print(\"Number of columns:\", combined_data.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_1apcL6jNVw",
        "outputId": "5be811fa-1044-40f7-ec29-187c9666987a"
      },
      "id": "3_1apcL6jNVw",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: 210384\n",
            "Number of columns: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nData types of each column:\")\n",
        "print(combined_data.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3DHIiL8jTgR",
        "outputId": "7ae3029d-2976-4c90-b4ad-b7562d24a3db"
      },
      "id": "H3DHIiL8jTgR",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data types of each column:\n",
            "No           int64\n",
            "year         int64\n",
            "month        int64\n",
            "day          int64\n",
            "hour         int64\n",
            "PM2.5      float64\n",
            "PM10       float64\n",
            "SO2        float64\n",
            "NO2        float64\n",
            "CO         float64\n",
            "O3         float64\n",
            "TEMP       float64\n",
            "PRES       float64\n",
            "DEWP       float64\n",
            "RAIN       float64\n",
            "wd          object\n",
            "WSPM       float64\n",
            "station     object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nMissing values in each column:\")\n",
        "print(combined_data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6BVpQbOjbnQ",
        "outputId": "e7a5be1b-17dd-42e9-f7d4-ef095c5235c7"
      },
      "id": "Y6BVpQbOjbnQ",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values in each column:\n",
            "No             0\n",
            "year           0\n",
            "month          0\n",
            "day            0\n",
            "hour           0\n",
            "PM2.5       4506\n",
            "PM10        3128\n",
            "SO2         4366\n",
            "NO2         6624\n",
            "CO         11157\n",
            "O3          5712\n",
            "TEMP         213\n",
            "PRES         214\n",
            "DEWP         218\n",
            "RAIN         209\n",
            "wd          1181\n",
            "WSPM         177\n",
            "station        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Importing the datasets\n",
        "data_dongsi = pd.read_csv('/content/PRSA_Data_Dongsi_20130301-20170228.csv')\n",
        "data_guanyuan = pd.read_csv('/content/PRSA_Data_Guanyuan_20130301-20170228.csv')\n",
        "data_gucheng = pd.read_csv('/content/PRSA_Data_Gucheng_20130301-20170228.csv')\n",
        "data_huairou = pd.read_csv('/content/PRSA_Data_Huairou_20130301-20170228.csv')\n",
        "data_nongzhanguan = pd.read_csv('/content/PRSA_Data_Nongzhanguan_20130301-20170228.csv')\n",
        "data_shunyi = pd.read_csv('/content/PRSA_Data_Shunyi_20130301-20170228.csv')"
      ],
      "metadata": {
        "id": "e3-g7kyM4Thk"
      },
      "id": "e3-g7kyM4Thk",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p6rlhsMp6JRl"
      },
      "id": "p6rlhsMp6JRl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging the datasets\n",
        "data_merged = pd.concat([data_dongsi, data_guanyuan, data_gucheng, data_huairou, data_nongzhanguan, data_shunyi], ignore_index=True)"
      ],
      "metadata": {
        "id": "UpBVd4o_49TS"
      },
      "id": "UpBVd4o_49TS",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing Duplicate Entries\n",
        "# This removes any row that is an exact duplicate of another\n",
        "data_merged.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "qWJ7YPZO5PHQ"
      },
      "id": "qWJ7YPZO5PHQ",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, you can specify a subset of columns to consider for identifying duplicates\n",
        "# data_merged.drop_duplicates(subset=['column1', 'column2'], inplace=True)\n",
        "\n",
        "# Show how many records are in the dataset after duplicates are removed\n",
        "print(f\"Number of records after removing duplicates: {data_merged.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE5bYfcf5XHf",
        "outputId": "e082ef33-318b-47d7-b01f-254f40de6109"
      },
      "id": "VE5bYfcf5XHf",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records after removing duplicates: 210384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows to verify changes\n",
        "print(data_merged.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee-MW5KA5Y_C",
        "outputId": "01e38ad2-8de2-45b1-be05-f721890138c7"
      },
      "id": "Ee-MW5KA5Y_C",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   No  year  month  day  hour  PM2.5  PM10  SO2   NO2     CO    O3  TEMP  \\\n",
            "0   1  2013      3    1     0    9.0   9.0  3.0  17.0  300.0  89.0  -0.5   \n",
            "1   2  2013      3    1     1    4.0   4.0  3.0  16.0  300.0  88.0  -0.7   \n",
            "2   3  2013      3    1     2    7.0   7.0  NaN  17.0  300.0  60.0  -1.2   \n",
            "3   4  2013      3    1     3    3.0   3.0  5.0  18.0    NaN   NaN  -1.4   \n",
            "4   5  2013      3    1     4    3.0   3.0  7.0   NaN  200.0  84.0  -1.9   \n",
            "\n",
            "     PRES  DEWP  RAIN   wd  WSPM station  \n",
            "0  1024.5 -21.4   0.0  NNW   5.7  Dongsi  \n",
            "1  1025.1 -22.1   0.0   NW   3.9  Dongsi  \n",
            "2  1025.3 -24.6   0.0  NNW   5.3  Dongsi  \n",
            "3  1026.2 -25.5   0.0    N   4.9  Dongsi  \n",
            "4  1027.1 -24.5   0.0  NNW   3.2  Dongsi  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_merged.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlVnKNUv66Qs",
        "outputId": "f1766808-e8f0-4e86-a962-d52700cf0594"
      },
      "id": "wlVnKNUv66Qs",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['No', 'year', 'month', 'day', 'hour', 'PM2.5', 'PM10', 'SO2', 'NO2',\n",
            "       'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'wd', 'WSPM', 'station'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}